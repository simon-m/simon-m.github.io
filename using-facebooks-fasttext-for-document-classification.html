
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="robots" content="" />

  <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,400italic' rel='stylesheet' type='text/css'>

    <link rel="stylesheet" type="text/css" href="./themes/stylesheet/style.min.css">

  <link rel="stylesheet" type="text/css" href="./themes/pygments/github.min.css">
  <link rel="stylesheet" type="text/css" href="./themes/font-awesome/css/font-awesome.min.css">


    <link href="https://simon-m.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Weblog Atom">





<meta name="author" content="Simon-M" />
<meta name="description" content="A short introduction to using FastText for document classification" />
<meta name="keywords" content="NLP, Text classification, Word embedding">

<meta property="og:site_name" content="Weblog"/>
<meta property="og:title" content="Using Facebook&#39;s FastText for document classification."/>
<meta property="og:description" content="A short introduction to using FastText for document classification"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="./using-facebooks-fasttext-for-document-classification.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2017-10-24 18:30:00+02:00"/>
<meta property="article:modified_time" content="2017-10-31 23:00:00+01:00"/>
<meta property="article:author" content="./author/simon-m.html">
<meta property="article:section" content="Machine learning"/>
<meta property="article:tag" content="NLP"/>
<meta property="article:tag" content="Text classification"/>
<meta property="article:tag" content="Word embedding"/>
<meta property="og:image" content="">

  <title>Weblog &ndash; Using Facebook&#39;s FastText for document classification.</title>


<script         src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML'>
</script>


</head>
<body>
  <aside>
    <div>
      <a href=".">
        <img src="./themes/img/profile.png" alt="What's in there?" title="What's in there?">
      </a>
      <h1><a href=".">What's in there?</a></h1>

<p>Random notes about data analysis at large</p>
      <nav>
        <ul class="list">
          <li><a href="./pages/links.html#links">Links</a></li>

        </ul>
      </nav>

      <ul class="social">
      </ul>
    </div>


  </aside>
  <main>

    <nav>
      <a href=".">    Home
</a>

      <a href="categories.html">Categories</a>
      <a href="tags.html">Tags</a>

      <a href="https://simon-m.github.io/feeds/all.atom.xml">    Atom
</a>

    </nav>

<article class="single">
  <header>
      
    <h1 id="using-facebooks-fasttext-for-document-classification">Using Facebook's FastText for document classification.</h1>
    <p>
          Posted on mar. 24 octobre 2017 in <a href="./category/machine-learning.html">Machine learning</a>


    </p>
  </header>


  <div>
    <h1>Context</h1>
<p>I am currently working on classifying some medical data in the form of examination notes,
the goal being to predict whether a patient has a pathology or not.
This text data has a few quirks compared to textbook examples of document classification:</p>
<ul>
<li>Documents (one per patient) are short: less than 30 words on average</li>
<li>The text is dirty</li>
<li>many word contain typos, resulting in multiple tmers refering to the same thing</li>
<li>many abbreviations are used and end up in conflicts</li>
<li>Many words and mostly important ones are subject-specific jargon and thus cannot be recovered
   using general-purpose spelling correctors.</li>
<li>The single binary label pathology/no_pathology is noisy because it is the result of partial manual
   annotation. more specifically, a subset of the dataset was selected for annotation based on a
   currated list of keywords (and their typo'd variations). The rest was labeled as "no_pathology".
   Moreover, the manual annotation was also carried out in a fairly limited time-frame which did not allow
   multiple pass on the same patients by several annotators.</li>
<li>The dataset in very unbalanced since around 1.2% of the patient are part of the "pathology" class.</li>
</ul>
<p>On the plus side, the dataset is rather large with ~600000 patients.</p>
<p>On the minus side, I have access to a fairly limited amount of computing power (no GPU, intel i3 with 4 Gb RAM).
Therefore, even though I am fairly attracted to the shiny neural networks-based methods
(in particular convolutional, recurrent and long-short term memory NN which seem to enjoy a fair share
of success) there is absolutely no way I can run them. Also, cloud-based solutions such as Amazon's AWS are out of
the question, the first reason for that being that the data should not leave the lab.</p>
<h1>Facebook's fastText</h1>
<p>After trying a bunch of different methods which will be the subject of another article,
I was reading on language models, in particular n-grams and word embeddings/representations
such as word2vec and GloVe, hoping to find new ideas for extracting relevant features from
my documents' text.</p>
<p>Both the n-gram and word representation are interesting in their own right but I am rather
impressed by the semantic properties of word2vec. However, word embedding methods are called
this way for a reason: the unit are words, which means each word gets vector representation.
I am therefore left with the follwing question: how to meaningfully combine these and get a document
representation?</p>
<p>I then stumbled upon an interesting article:
<a href="https://arxiv.org/abs/1607.01759">Bag of Tricks for Efficient Text Classification</a>.
In short, the approach described by the authors consists in defining word (or n-gram) representation
<em>Ã  la</em> word2vec, simply average them to get a sentence representation and feed that to a linear
classifier.</p>
<p>I like this approach for several reasons: it uses the apparently powerful word2vec framework,
it is conceptually simple, it compares favorably to baselines and more sophisticated models,
it is fast and in particular much much faster than the neural network-based models I cannot
afford, and finally , it is already implemented in the
<a href="https://github.com/facebookresearch/fastText/">fastText library</a>.</p>
<p>I am therefore going to try my luck and use fastText's classifier to gauge its ability to
classify my data. If it works well I will also try to use the sentence representations as
extra features along with the LDA topic mixtures I have used so far.</p>
<p>Note that fastText is not limited to classification: it can be used in an unsupervised fashion
to get word and sentence embeddings.</p>
<h2>FastText for Windows</h2>
<p>First hurdle: fastText is designed to build under Unix-like systems.
that's a bummer as despite being a long-standing user and fan of Linux systems,
I am stuck with Windows at work.
Fortunately, someone may have felt the same and shared a
<a href="http://cs.mcgill.ca/~mxia3/FastText-for-Windows/">Windows version</a> of the library.
Thumbs up to you <a href="http://cs.mcgill.ca/~mxia3">Meng Xuan Xia</a>.</p>
<p>After a quick and painless compilation with MS Visual C++ (my first time using it), I am
ready to start.</p>
<h1>Getting started</h1>
<p>I am mainly giving  short version of the <a href="https://github.com/facebookresearch/fastText/">documentation</a>
and <a href="https://github.com/facebookresearch/fastText/blob/master/tutorials">tutorials</a>, so you
will probably need to read them too.</p>
<p>The command-line interface (CLI) is very simple to use and the input format is very minimalistic
and convenient (I am looking at you Weka and ARFF).</p>
<p>The training set format is as such:</p>
<div class="highlight"><pre><span></span>This is an example sentence __label__example
This is one is not (yes it is though) __label__not_example
</pre></div>


<p>Basically, each sentence/document is written as is on a single line and the labels are
prefixed with __label__ (this can be customized using the -label option on the CLI).
In this case, I simply encode the single binary label as two labels "__label__pathology" and
"__label__no_pathology".</p>
<p>Training a default classifier is dead simple with the "supervised" command.</p>
<div class="highlight"><pre><span></span>fastText.exe supervised -input training_set.txt -output default_model
</pre></div>


<p>The performance of the resulting model can then be investigated using the test command</p>
<div class="highlight"><pre><span></span>fastText.exe test default_model.bin test_file.txt 1;
</pre></div>


<p>The "1" here is the default value for the number of top label to be used as the prediction.
In the general case, a value of "1" will give as prediction the best label only.
In my case, since I have a single binary label, using "1" is the way to go.
This prints the precision achieved on the test set.</p>
<p>In this case, precision is not a good measure because of the very strong unbalance of the dataset.
Always predicting "no_pathology", one can expect precision and recall to reach ~98.8%.
Such a high baseline makes it difficult to assess whether this classifier is better than the
dummy "always predict no-pathology" one.</p>
<p>Fortunately, I can rely on the "predict" command to get predictions and compute the confusion matrix
or any other metric such as Matthews Correlation Coefficient (MCC).</p>
<div class="highlight"><pre><span></span>fastText.exe predict default_model.bin test_file.txt 1 &gt; predictions.txt;
</pre></div>


<p>Still, I need a more detailed account of the classifier's performance. Specifically,
I would like to get a maximum of true positives (TP) (don't we all?) while keeping the number of
false positives (FP) close to TP. This has to do with the way the
classifier will be used, namely screening and human validation of the positive predictions.
The goal is to give a reasonable number of screened patients to the validators.
I therefore need to have access to a probability-like number instead of 0 / 1 decisions in order
to vary the "positive" cutoff during subsequent analyses.</p>
<p>For that, I use the "predict-prob" command of fasttext.</p>
<div class="highlight"><pre><span></span>fastText.exe predict-proba default_model.bin test_file.txt 1 &gt; class_probabilities.txt;
</pre></div>


<h1>Parameters</h1>
<p>A short description of the parameters is provided in the documentation, but I will
expand a little here on the most important ones.</p>
<hr>
<p>The "-loss" option allows you to choose the loss which is optimized for.</p>
<p>The default value is "ns" for negative sampling. It is an approximation of the softmax loss
based on sampling "negative examples".</p>
<p>Briefly and very roughly, the goal of word2vec is to find an embedding of words, i.e. a vector
representation for each word in a space of fixed dimension.
Given a <em>context</em> i.e. words surrounding a word of interest (e.g. in a fixed size window around it),
a good embedding should satisfy the following:</p>
<ol>
<li>the dot product between the vectors of a word and a context often found together should be large.</li>
<li>this dot product must be small for words and contexts which rarely co-occur</li>
</ol>
<p>Given the vector representation \(w_i\) of a word and a context \(c_j\), the goal is
therefore to maximize \(\frac{w_i \cdot c_j}{sum_w(w \cdot c_j)}\). The normalization
is a sum over all words which can be prohibitively large and yield very long computation
times.</p>
<p>Remark: this is a gross simplification; the actual softmax loss is actually
\(-log P(w_i | c_j) = -log(e^{w_i \cdot c_j} / sum_w(e^{w \cdot c_i}))\) which
should be minimized instead of maximized.</p>
<p>An alternative is therefore to replace the sum over all words by  a sum over a random
sample, under the reasonable assumption that most are "negative", i.e. rarely co-occur
with a given context. This resutls in the negative sampling loss. See also this
<a href="https://stackoverflow.com/questions/27860652/word2vec-negative-sampling-in-layman-term">stackoverflow post</a>.</p>
<p>The "softmax" value results in using the regular softmax loss which is much <em>much</em> slower.</p>
<p>The "hs" value uses hierarchical softmax. The goal is to organize the set of all words in a tree so that
the sum over all words reduces instrad to a sum over one path in the tree.</p>
<p>Namely, the probability \(P(w_i | c_j)\) is computed by first building
a <a href="https://en.wikipedia.org/wiki/Huffman_coding">Huffman tree</a> with words as leaves,
so that most common words are found at smaller depth.
Each internal node \(n_i\) has two children and their associated probabilities \(p_i\) and
\(q_i = 1 - p_i\) where \(p_i\) depends both on \(c_j\) and a vector which is learned during training.
The probaility \(P(w_i | c_j)\) is then computed by following the path from the root to the
\(w_i\) and multiplying the \(p_i\) or \(q_i\) depending on which child is followed.
Since the depth of a balanced tree with \(n\) leaves is \(O(log(n))\), this reduces the computation of
the softmax loss from \(O(W)\) to \(O(log(W)\) for \(W\) words. A more detailed explanation with nice
graphics can be found <a href="http://building-babylon.net/2017/08/01/hierarchical-softmax/">here</a>.</p>
<p>For a more rigorous description of negative sampling and hierarchical softmax, see
<a href="https://arxiv.org/abs/1310.4546">this article</a> and references therein.
In general, ns or hs are the only way to train the model in reasonable time. As a rule of thumb,
ns requires several epochs to be accurate (-epoch flag) wheread hs does not benefits from more epoch
(<a href="https://groups.google.com/forum/#!msg/word2vec-toolkit/WUWad9fL0jU/LdbWy1jQjUIJ">as stated here</a>).</p>
<hr>
<p>The "-bucket" option is used to tune the number of buckets used in the hash table. There is a
trade-off between accuracy and memory used as a smaller value implies more collisions.</p>
<hr>
<p>The "-lr" option tunes the learning rate. In general, a larger value means faster trainig and a
potentially less accurate model because of a higher risk of getting stuck in local minimum.</p>
<h1>Some results</h1>
<p>After a rather light parameter tuning phase, the best cutoff to balance TP and FP results in
a ~2/3 precision. Interestingly, this is almost the best that can be reached.
Indeed, lowering the threshold further (i.e. predicting more and more patients as "pathology") yields
very marginal changes on the precision, TP and FP until reaching a threshold where everything is predicted
as "pathology". This is because most of the low probabilities are all clustered very closeley around the
same value.</p>
<p>All in all, these results are fairly good considering I did not have to engineer any features and spent
little time optimizing the parameters.
The next step is to see whether word2vec features could benefit a classifier when used along LDA
topic mixtures.</p>
<h1>Further thoughts:</h1>
<p>I stumbled upon other alternatives in a similar philosophy:</p>
<ul>
<li><a href="https://radimrehurek.com/gensim/models/doc2vec.html">Gensim's Doc2Vec</a> does exactly what it
  says: it computes the embedding of whole documents/sentences which can then be fed to a classifier.
  Note: Gensim also implements word2vec and FastText.</li>
<li>Using word2vec/FasText, compute a component-wise max or min or average over all word representations
  and use the resulting vector as the sentence embedding. Computing all three min and max and average and
  concatenating them can also be used to get another embedding. Idea from this
  <a href="https://stats.stackexchange.com/questions/221715/apply-word-embeddings-to-entire-document-to-get-a-feature-vector">stackexchange post</a>
  and <a href="https://arxiv.org/abs/1607.00570">this paper</a>.</li>
</ul>
<h1>References:</h1>
<ul>
<li><a href="https://arxiv.org/abs/1607.01759">https://arxiv.org/abs/1607.01759</a></li>
<li><a href="https://github.com/facebookresearch/fastText/">https://github.com/facebookresearch/fastText/</a></li>
<li><a href="https://github.com/facebookresearch/fastText/blob/master/tutorials">https://github.com/facebookresearch/fastText/blob/master/tutorials</a></li>
<li><a href="https://stackoverflow.com/questions/27860652/word2vec-negative-sampling-in-layman-term">https://stackoverflow.com/questions/27860652/word2vec-negative-sampling-in-layman-term</a></li>
<li><a href="https://groups.google.com/forum/#!msg/word2vec-toolkit/WUWad9fL0jU/LdbWy1jQjUIJ">https://groups.google.com/forum/#!msg/word2vec-toolkit/WUWad9fL0jU/LdbWy1jQjUIJ</a></li>
<li><a href="https://arxiv.org/abs/1310.4546">https://arxiv.org/abs/1310.4546</a></li>
<li><a href="http://building-babylon.net/2017/08/01/hierarchical-softmax/">http://building-babylon.net/2017/08/01/hierarchical-softmax/</a></li>
<li><a href="https://en.wikipedia.org/wiki/Huffman_coding">https://en.wikipedia.org/wiki/Huffman_coding</a></li>
<li><a href="https://stats.stackexchange.com/questions/221715/apply-word-embeddings-to-entire-document-to-get-a-feature-vector">https://stats.stackexchange.com/questions/221715/apply-word-embeddings-to-entire-document-to-get-a-feature-vector</a></li>
<li><a href="https://radimrehurek.com/gensim/models/doc2vec.html">https://radimrehurek.com/gensim/models/doc2vec.html</a></li>
<li><a href="https://arxiv.org/abs/1607.00570">https://arxiv.org/abs/1607.00570</a></li>
</ul>
  </div>
  <div class="tag-cloud">
    <p>
      <a href="./tag/nlp.html">NLP</a>
      <a href="./tag/text-classification.html">Text classification</a>
      <a href="./tag/word-embedding.html">Word embedding</a>
    </p>
  </div>



    <div class="addthis_relatedposts_inline">


</article>

    <footer>
<p>&copy;  2017</p>
<p>    Powered by <a href="http://getpelican.com" target="_blank">Pelican</a> - <a href="https://github.com/alexandrevicenzi/flex" target="_blank">Flex</a> theme by <a href="http://alexandrevicenzi.com" target="_blank">Alexandre Vicenzi</a>
</p>    </footer>
  </main>




<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " Weblog ",
  "url" : ".",
  "image": "",
  "description": "Notes and ressources about data analysis, machine learning, statistics and epidemiology"
}
</script>

</body>
</html>